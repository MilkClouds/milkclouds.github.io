---
layout: post
title: '최근 읽은 흥미로운 이야기 - 한글 난독화'
author: MilkClouds
comments: true
date: 2021-03-04 00:35
tags: [science]

---

텍스트 분류 모델을 공격하는 기법으로, BERT, TextFooler와 같은 기법이 있다. 그리고 이와 관련된 학술적 논의도 진행되고 있다. [나동빈님 유튜브 - Is BERT really robust?](https://youtu.be/EF-IYFTKZiE)를 참고하면 쉽게 이해가 될 것이다.  

위의 유튜브 내용을 요약하자면, 'contrived situation'라는 글귀 거의 비슷한 뜻을 가진 'engineered circumstances'로 바꿔서, 텍스트 분류 모델의 분류 값을 Negative에서 Positive로 바꾼다는 것이다. 사소한 단어 변경으로도 분류 값을 바꿔버릴 수 있는 기법이다. 이 기법이 중요할 수 있는 이유는, 인공지능 자동차와 같이 머신비전과 분류를 활용할 때 사소한 노이즈를 섞어줬더니(나동빈님 유튜브 영상에서도 이 내용을 다룬다) 기둥을 사람으로 인식하는 경우가 생길 수 있기 때문이다.  



그리고 아래 글은 내가 최근 읽어본 글로, "한글 난독화" 서비스이다. 외국 제품, 숙박시설 등에 대한 리뷰를 한국어로 했을 때, 숙박시설 주인이 그 리뷰를 번역기로 돌려서 영어로 읽어보고 부정적인 리뷰면 삭제하는 경우가 있다. 그러한 경우를 대비해서, 한국인이라면 읽을 수 있지만 번역기를 돌렸을 때 제대로 번역이 되지 않는 한국어 문장을 만드는 내용이다.  

[한글 난독화 - 테크플러스 블로그 글](https://blog.naver.com/tech-plus/222261883483)  


내용을 보면 '서비스가 엉망이고요'를 '섟빇슧갃 엉망읷곣욗'으로 바꿔서 번역을 방해하는 것과 같이, 얼핏 보면 웃기고 조잡해 보이는 기법이다. 그러나, 위에서 말한 TextFooler의 기법을 적용한다면 단어 몇개를 비슷한 의미의 단어로 바꿔서 번역 결과를 아예 바꿔버릴 수도 있고(다만 개인적인 예상으로, 분류 모델에 비해 번역 모델은 교란하기가 좀 어려울 듯 하다), 관련된 학술적 논의에 언급될 수도 있고, 어쩌면 응용될 여지도 있지 않을까 싶다.  
